(overview:post)=

# Post-processing

After the FSI simulations, the last step of `VaSP` is post-processing the results.  
The `src/vasp/post_processing` directory is organized into several sub-packages and modules, each dedicated to different aspects of postprocessing for the `VaSP` project.  
The primary focus is on handling mesh data (`postprocessing_mesh`), postprocessing using FEniCS (`postprocessing_fenics`), and postprocessing with HDF5 files (`postprocessing_h5py`). Here’s an outline of the structure:

```
src/
└── vasp/
    └── post_processing/
        ├── __init__.py
        ├── log_plotter.py
        ├── postprocessing_common.py
        ├── predeform_mesh.py
        |
        ├── postprocessing_mesh/
        │   ├── __init__.py
        │   ├── create_refined_mesh.py
        │   ├── postprocessing_mesh_common.py
        │   └── separate_mesh.py
        |
        ├── postprocessing_fenics/
        │   ├── __init__.py
        │   ├── compute_hemodynamics.py
        │   ├── compute_stress_strain.py
        │   ├── create_hdf5.py
        │   ├── create_separate_domain_visualization.py
        │   └── postprocessing_fenics_common.py
        |
        └── postprocessing_h5py/
            ├── __init__.py
            ├── chroma_filters.py
            ├── create_hi_pass_viz.py
            ├── create_spectrograms_chromagrams.py
            ├── create_spectrum.py
            ├── postprocessing_common_h5py.py
            └── spectrograms.py
```

In the following, we will give an overview and explanations for each scripts.

## **Top-Level Directory: `post_processing`**

   - **General Utilities**: Contains general utility scripts `log_plotter.py`, `predeform_mesh.py`, and `postprocessing_common.py`.  

   - `log_plotter.py` - The usage is explained [here](simulation:log_plotter). This is to extract information from a log file generated during the run, and is particularly useful when running FSI simulations on the cluster.  

   - `predeform_mesh.py` - This is used to pre-deform the mesh prior to running pulsatile FSI. It is assumed that pre-deformation simulation has been already performed.  
   This script is available as a following command:
   ```console
    vasp-predeform-mesh --folder /path/to/your/result --scale-factor -1
   ```

## **postprocessing_mesh**
   - **Purpose**: Focuses on handling mesh data used in simulations for later post-processing purposes.
   - `create_refined_mesh.py` - In `turtleFSI`, there is a way to save visualization file with refined mesh via `save-deg` parameter. To utilize such a functionality in the other parts of the post-processing, it is necessary to create a stand-alone refined mesh. This script is dedicated for that and can be run as follows:
   ```console
   vasp-refine-mesh --folder /path/to/your/result
   ```
   Normally, `vasp-refine-mesh` will find the original (non-refined) mesh automatically, but the user can specify the path to the mesh using `--mesh-path` as a command-line argument.  
   As a result, the user should get a HDF5 file named `mesh_refined.h5` under `Mesh` folder in your result folder.  
   The following image is an example of original and refined mesh.

   ```{figure} figures/refined_mesh.png
   ---
   name: refined_mesh
   ---
   An example of refined mesh generated by `vasp-refine-mesh` function
   ```

   - `separate-mesh.py` - By default, `turtleFSI` shows visualizations with a whole domain (fluid + solid). However, it is convenient to visualize the results for fluid and solid separately. Furthermore, we will utilize those separated meshes for computing variables that are only relevant for each domains, such as stresses inside the solid.  
   To generate separated meshes, please run
   ```console
   vasp-separate-mesh --folder /path/to/your/result
   ```

   Same as `vasp-refine-mesh`, `VaSP` will automatically find a mesh and will generate separate meshes for both original and refined mesh. Therefore, after running both `vasp-refine-mesh` and `vasp-separate-mesh`, `Mesh` folder inside your result folder should look like this:
   ```
   Mesh/
   ├── mesh.h5
   ├── mesh_fluid.h5
   ├── mesh_solid.h5
   ├── mesh_refined.h5
   ├── mesh_refined_fluid.h5
   └── mesh_refined_solid.h5
   ``` 
   The following image shows an example of separated fluid and solid domain with refined mesh.

   ```{figure} figures/separate_mesh.png
   ---
   name: separate_mesh
   ---
   An example of fluid and solid mesh generated by `vasp-separate-mesh` function
   ```


## **postprocessing_fenics**
   - **Purpose**: Dedicated to postprocessing tasks related to the FEniCS, for computing hemodynamic indices, stress and strain metrics, creating HDF5 files, visualizing separate domains, and common FEniCS postprocessing utilities.
   
   - `create_hdf5.py` - This script is the initial step in post-processing with FEniCS. It's necessary because FEniCS cannot directly read `.xdmf` visualization files for post-processing. The script generates a folder `Visualization_separate_domain` and   two HDF5 files inside:

   1. `u.h5`: Contains velocity data for the fluid domain
   2. `d_solid.h5`: Contains displacement data for the solid domain

   These HDF5 files can be used by FEniCS for computing various metrics.

   Usage:

   The script is available as a command-line tool:

   ```console
   vasp-create-hdf5 --folder /path/to/your/result
   ```
   Additional options available as command-line arguments:

   Time range selection:
      --start-time <value>  : Specify the start time
      --end-time <value>    : Specify the end time
      --stride <value>      : Set the stride for time steps
   Domain extraction:
      --extract-entire-domain : Extract displacement for the entire domain

   Example with options:
   ```console
   vasp-create-hdf5 --folder /path/to/your/result --start-time 0.951 --end-time 1.902 --stride 2 --extract-entire-domain
   ```
   This command will process data from time 0.951 to 1.902 (usually second cardiac cycle), using every second time step, and extract displacement for the entire domain. 
   Note:
   This script runs only in serial.

   - `create_separate_domain_visualization.py` - This script generates separate visualization files for fluid and solid domains, using the HDF5 files created by the previous step.
   
   Usage:
   Run the following command:

   ```console
   vasp-create-separate-domain-viz --folder /path/to/your/result
   ```

   Output:
   The script creates files inside `Visualization_separate_domain`:

   `velocity_fluid.xdmf`: Visualization file for fluid velocity
   `displacement_solid.xdmf`: Visualization file for solid displacement

   These files are generated based on the `.h5` files previously created.
   Note:
   This script supports parallel execution with MPI for potentially faster processing. To run in parallel, use:

   ```console
   mpirun -np <number_of_processes> vasp-create-separate-domain-viz --folder /path/to/your/result
   ```

   - `compute_hemodynamics.py` - This script computes hemodynamic indices defined in `VaMPy` (see Table1 at https://kvslab.github.io/VaMPy/quantities.html). The only difference from `VaMPy` is that WSS is defined as a first-order Discontinuous Galerkin function (DG1). This is because computing WSS involves taking the gradient of second-order Continuous Galerkin (CG2) function.

   Usage:
   Run the following command:
   
   ```console
   vasp-compute-hemo --folder /path/to/your/result
   ```

   This script can be run in parallel with MPI.

   Output:
   All the hemodynamic indies will be stored inside a newly generated folder `Hemodynamic_indices`

   - `compute_stress_strain.py` - This script computes the following solid mechanical metrics:

   1. True (Cauchy) Stress -- tensor
   2. Green-Lagrange Strain -- tensor
   3. Maximum Principal Stress (True/Cauchy) -- scalar
   4. Maximum Principal Strain (Green-Lagrange) -- scalar
   
   Usage:
   Run the following command:
   
   ```console
   vasp-compute-stress --folder /path/to/your/result
   ```
   This script can be run in parallel with MPI.

   Output:
   All the results will be stored inside a newly generated folder `StressStrain`



## **postprocessing_h5py**
   - **Purpose**: Focuses on postprocessing tasks involving HDF5 files, utilizing the `h5py` library.
   - **Contents**: Includes scripts for creating spectrograms, chromagrams, high-pass visualizations, spectra, and applying chroma filters, along with common H5PY-related postprocessing utilities.
